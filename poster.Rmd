---
title: Job Industry Classification
author:
  - name: Jiancong Qi
    affil: 1
  - name: Jinyi Li
    affil: 1
  - name: Joy Wang
    affil: 1
  - name: Zheng Wang
    affil: 1
  - name: Wenxin Zhou
    affil: 1
affiliation:
  - num: 1
    address: Department of Statistics, UCLA
# - num: 2
#   address: Some other affiliation
column_numbers: 3
font_family: Helvetica
primary_colour: "#2774AE"
secondary_colour: "#FFD100"
accent_colour: "#003B5C"
affiliation_textcol: "#FFD100"
logoright_name: https&#58;//raw.githubusercontent.com/brentthorne/posterdown/master/images/betterhexlogo.png
logoleft_name: http&#58;//www.firststar.org/wp-content/uploads/2015/02/ucla1.jpg
## https://ev0awwmgj4-flywheel.netdna-ssl.com/wp-content/uploads/images/products/products-University-of-CA-Los-Angeles-Seal.jpg
output: 
  posterdown::posterdown_html:
    self_contained: false
bibliography: packages.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

In this poster, we demonstrate a practice of industry classifications with job descriptions. In the dataset of the DataFest 2018, around 90% of the job postings do not have industry information. Using the words in the job description, we try to classify the job postings without industry information to different industries. 

## Objectives

Build model to perform job industry classification

# Methods

1.Seperate the job postings with industry information into training and testing sets.
2.
3.



# Results

Let's see the results from a SVM model!

```{r mytable, out.width='80%', warning=FALSE}
library(mvtnorm)
library(e1071)
# generation of data
# try making different data sets
xa <- rmvnorm(10,mean = c(0,0), sigma = diag(2))
xb <- rmvnorm(10, mean = c(2,2), sigma = diag(2))
x <- rbind(xa, xb)
df <- data.frame(x, y =c(rep('-1', 10), rep(1, 10)))
knitr::kable(df, caption = 'Table of our data',align = 'c',"html")
plot(df$X1,df$X2, col = df$y, pch = 19, asp = 1) # create a plot of the mixture
```



```{r morefigs, out.width='80%', echo=TRUE, fig.cap='Amazing, right?!', fig.height=5}
# the SVM model. Try changing kernel type between linear/radial, and using different values of gamma and cost
model <- svm(y ~ . , data = df, scale = FALSE, kernel = "radial", gamma = 1, cost = 1)
# The code to plot the decision boundary
## used to create a grid of red/black points 
x1range <- seq(-3,4.2,by = 0.1); x2range <- seq(-2,3,by = 0.1)
xgrid <- expand.grid(X1 = x1range, X2 = x2range)
ygrid <- predict(model, xgrid, decision.values = TRUE)
# extract svm's decision values for each point, which will be used to draw contour lines
decision_vals = attributes(ygrid)$decision
plot(xgrid, col = as.numeric(ygrid), pch = 20, cex = .2) # plot the grid of points colored by the decision
points(df$X1, df$X2, col = df$y, pch = 19) # add the points in the original data
## add some contour lines
contour(x1range, x2range, matrix(decision_vals, nrow = length(x1range)), level = 0, add = TRUE, lwd = 2)
contour(x1range, x2range, matrix(decision_vals, nrow = length(x1range)), level = 0.5, add = TRUE, col = "black")
contour(x1range, x2range, matrix(decision_vals, nrow = length(x1range)), level = -0.5, add = TRUE, col = "red")
```

# Next Steps

Aliquam sed faucibus risus, quis efficitur erat. Vestibulum semper mauris quis tempus eleifend. Aliquam sagittis dictum ipsum, quis viverra ligula eleifend ut. Curabitur sagittis vitae arcu eget faucibus. In non elementum felis. Duis et aliquam nunc. Nunc pulvinar sapien nunc, vel pretium nisi efficitur in. Fusce fringilla maximus leo et maximus. Fusce at ligula laoreet, iaculis mi at, auctor odio. Praesent sed elementum justo. Aenean consectetur risus rhoncus tincidunt efficitur. Praesent dictum mauris at diam maximus maximus [@R-posterdown].

# Conclusion

**Support vector machine** is one of the powerful supervised learning models that can analyzed data used for classification and regression analysis. 

```{r, include=FALSE}
knitr::write_bib(c('knitr','rmarkdown','posterdown','pagedown'), 'packages.bib')
```

# References
